{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3446e8d",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "- 기초지식\n",
    "  - Probability Distribution\n",
    "  - Visualization(산점도, 막대그래프, 선그래프, 히트맵, 서브플롯, 트리맵, 도넛차트, 버블차트, 히스토그램, 체르노프 페이스, 스타차트, 다차원척도법, 평행좌표계\n",
    "도식화와 시각화)\n",
    "- 표본 추출법(단순랜덤 추출법, 계통추출법, 집락추출법, 층화추출법)\n",
    "- 사전검정\n",
    "  - 정규성검정(콜모고로프 스미르노프 검정, QQ도, Anderson-Darling test, 샤크로-윌크 검정)\n",
    "  - 등분산검정\n",
    "- 가설검정\n",
    "  - Ttest, Ftest\n",
    "  - 분산분석\n",
    "    - 일원배치 분산분석 및 사후분석(던칸의 MRT, 피셔의 LSD, Scheffe의 방법)\n",
    "    - 이원배치 분산분석 및 교호작용 해석\n",
    "  - 교차분석(적합도 검정, 독립성 검정, 동질성 검정)\n",
    "  - 상관분석(피어슨, 스피어만, 켄달 타우, 상관계수 검정)\n",
    "- `다중검정`\n",
    "  - https://syj9700.tistory.com/6\n",
    "- 비모수검정(부호검정, 윌콕슨의 순위합 검정, 윌콕슨의 부호순위합검정, 만위트니의 U검정, 런검정)\n",
    "- 회귀분석\n",
    "  - 가정검토(선형성, 등분산성-잔차도, 정규성-히스토그램/QQplot/Shapiro-wilk, 오차항의 독립성-더빈왓슨검정)\n",
    "  - 단순선형회귀분석(회귀계수 검정, 결정계수 계산-SST/SSR/SSE, 회귀직선의 적합도 검토)\n",
    "  - 다중선형회귀분석(회귀계수 검정, 회귀식, 결정계수 계산, 모형의 통계적 유의성, 교호작용, 다중공선성-PCA회귀, VIF 상위변수 제거)\n",
    "  - 정규화 선형회귀(Ridge회귀, Lasso회귀, Elastic Net 회귀)\n",
    "  - 일반화 선형회귀\n",
    "  - 다항회귀분석\n",
    "  - 스플라인 회귀\n",
    "  - 로지스틱 회귀\n",
    "  - 회귀분석의 기울기에 영향을 주는 영향점 진단(Cook's Distance, DFBETAS, DFFITS, Leverage H)\n",
    "  - 변수선택(전진선택법, 후진제거법, 결정계수, Mallow's Cp, 단계적선택법 - AIC/BIC)\n",
    "- `판별분석`\n",
    "- 차원축소\n",
    "  - 주성분분석(Scree plot, 누적기여율, 주성분 별 가중치, Biplot)\n",
    "  - 다차원척도법(계량적MDS, 비계량적 MDS)\n",
    "  - 요인분석\n",
    "  - 매니폴드학습, PCA, NMF\n",
    "- 시계열분석\n",
    "  - 분해시계열\n",
    "  - ARIMA(정상성(`ADF`, `KPSS` test) 평가, 차분 수행, 모델링 및 `Ljung-Box test`, ACF/PACF를 통한 모델 선택)\n",
    "  - `SARIMA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b8df1",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "- 기초지식\n",
    "  - Confusion Matrix(정분류율, 오분류율, 특이도, 민감도, 정확도, 재현율, F1 Score)\n",
    "  - RoC Curve, AUROC\n",
    "  - Lift Chart (Frequency of buy, captured response, response, lift)\n",
    "  - Bias-variance Trade-off 내용\n",
    "- Data Preprocessing\n",
    "  - Imputation(단순대치, 평균 대치, 단순확률 대치 (Hot-deck, nearest neighbor), 다중 대치, knnImputation, centralimputation)\n",
    "  - Outlier(극단값 절단, 조정)\n",
    "  - Numeric Feature Transform(수치형 변수 변환(로그변환, 제곱근변환, 지수변환, 제곱변환, Box-cox 변환, 표준화, 정규화, 이산화)\n",
    "  - Category Feature Encoding(OnehotEncoding, MeanEncoding, 대규모 범주형 변수처리)\n",
    "- Classification Model\n",
    "    - 의사결정나무\n",
    "      - 알고리즘(CART, C5.0, C4.5, CHAID)\n",
    "      - 가지치기 방법\n",
    "      - 평가지표(카이제곱통계량, 지니지수, 엔트로피, F통계량)\n",
    "    - SVM\n",
    "    - KNN\n",
    "    - Bayesian Classification\n",
    "    - 가우시안 혼합모델\n",
    "    - Ensemble\n",
    "      - Bagging과 Boosting, Stacking 차이\n",
    "      - Adaboost\n",
    "      - Random Forest\n",
    "      - ExtraTree\n",
    "      - XGB, LGBM, Catboost\n",
    "- Model Generalize\n",
    "  - CV(HoldOut, Kfold, StratifiedKfold, Bootstrap 등)\n",
    "  - Data Imbalance(업샘플링 (SMOTE, Boaderline SMOTE, Adasyn), 다운샘플링)\n",
    "- Hyperparameter Tunning(Optimization)\n",
    "  - Grid Search, Random Search, Bayesian Search 등\n",
    "- 군집분석\n",
    "  - 계층적군집\n",
    "    - 합병형 Bottom-up 방식(최단연결법, 평균연결법, 와드연결법, 최장연결밥, 중심연결법)\n",
    "    - 분리형 top-down 방식(다이아나 방법)\n",
    "    - 덴드로그램\n",
    "  - 비계층적군집\n",
    "    - 프로토타입 centroid-based (K-centroid 군집, K-means 군집, K-median 군집, K-medoid 군집, Fuzzy 군집)\n",
    "    - 분포기반GMM(혼합분포군집; EM알고리즘, 로그-가능도 함수)\n",
    "    - 밀도기반(중심밀도군집, DBSCAN, OPTICS, DENCLUE)\n",
    "    - 격자기반(STING, WaveCluster, CLIQUE)\n",
    "  - 군집분석 거리지표(유클리디안 거리, 마할라노비스 거리, 체비셰프 거리, 맨하탄 거리, 캔버라 거리, 민코우스키 거리, 자카드 거리, 코사인 거리)\n",
    "  - 평가지표(실루엣 계수, Dunn Index)\n",
    "- SOM\n",
    "- 연관규칙탐사\n",
    "  - 장바구니분석(Apriori, FP Growth, FPV, Eclat)\n",
    "  - 연관규칙\n",
    "  - 서열분석 (순차패턴, 시차-연관분석; Sequence Analysis)\n",
    "  - 평가지표(지지도, 신뢰도, 향상도)\n",
    "- `사례기반 추론`\n",
    "  - https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=imsam77&logNo=221228778436"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27577fc",
   "metadata": {},
   "source": [
    "### 참고도서\n",
    "- 가도와키 다이스케, 사카타 류지, 호사카 게이스케, 히라마쓰 유지, 데이터가 뛰어노는 AI 놀이터, 캐글 (서울: 한빛미디어)\n",
    "- 로웰 아티엔자, 케라스로 구현하는 고급 딥러닝 알고리즘 (경기: 위키북스, 2019)\n",
    "- 벤자민 벵포트, 레베카 빌브로, 토니 오제다, 파이썬으로 배우는 응용 텍스트 분석 (경기: 제이펍, 2019)\n",
    "- 스티븐 마슬랜드, 알고리즘 중심의 머신러닝 가이드 제2판 Machine Learning: An Algorithmic Perspective, Second Edition (경기: 제이펍, 2017)\n",
    "- 안드레아스 뮐러, 세라 가이도, 파이썬 라이브러리를 활용한 머신러닝 번역개정판 (서울: 한빛미디어, 2019)\n",
    "- 앨리스 젱, 아만다 카사리, 피처 엔지니어링 제대로 시작하기 (서울: 에이콘, 2019)\n",
    "- 에일린 닐슨, 실전 시계열 분석 (서울: 한빛미디어, 2021)\n",
    "- 웨스 맥키니, 파이썬 라이브러리를 활용한 데이터 분석 (서울: 한빛미디어, 2016)\n",
    "- 윤종식, ADP 데이터 분석 전문가 (부산: (주)데이터에듀, 2021)\n",
    "- 윤종식, ADsP 데이터 분석 준전문가 (부산: (주)데이터에듀, 2021)\n",
    "- 피터 브루스, 앤드루 브루스, 피터 게데크, 데이터 과학을 위한 통계 2판 (서울: 한빛미디어, 2021)\n",
    "\n",
    "### 참고사이트\n",
    "- [성실한 나무] https://lovelydiary.tistory.com/381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f670437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
